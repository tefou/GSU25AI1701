import sys
import os
# ==== S·ª≠a ƒë∆∞·ªùng d·∫´n cho import module custom ====
sys.path.append(os.path.abspath("."))           # Th∆∞ m·ª•c g·ªëc d·ª± √°n
sys.path.append(os.path.abspath("./R3GAN"))     # ƒê·ªÉ import ƒë∆∞·ª£c torch_utils + R3GAN.R3GAN

import streamlit as st
import pandas as pd
import numpy as np
import cv2
from PIL import Image
import torch
import pickle
import json
import xml.etree.ElementTree as ET
from streamlit_drawable_canvas import st_canvas
import math

# ===== 1. Import Generator chu·∫©n t·ª´ R3GAN =====
from R3GAN.Networks import Generator

# ===== 2. Build Generator v·ªõi ƒë√∫ng tham s·ªë =====
def build_generator():
    return Generator(
        InputChannels=1, 
        WidthPerStage=[256, 512, 512 , 256],
        CardinalityPerStage=[2, 2, 2, 2],
        BlocksPerStage=[6, 4, 4, 6],
        ExpansionFactor=2,
        KernelSize=3,
        ResamplingFilter=[1, 2, 1]
    )

# ===== 3. Load state_dict t·ª´ .pkl =====
def load_generator_state_dict(pkl_path):
    with open(pkl_path, "rb") as f:
        data = pickle.load(f, encoding="latin1")
    G_ema = data.get('G_ema', None)
    state_dict = None
    if G_ema is not None:
        if hasattr(G_ema, 'state_dict'):
            state_dict = G_ema.state_dict()
        elif isinstance(G_ema, dict) and 'state_dict' in G_ema:
            state_dict = G_ema['state_dict']
        elif hasattr(G_ema, '__dict__'):
            state_dict = G_ema.__dict__.get('state_dict', None)
    return state_dict

@st.cache_resource
def load_model():
    model_path = "network-snapshot-000000020.pkl"
    try:
        sd = load_generator_state_dict(model_path)
        if sd is None:
            st.error("‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c state_dict t·ª´ model.")
            return None
        gen = build_generator()
        gen.load_state_dict(sd, strict=False)
        gen.eval()
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        gen = gen.to(device)
        st.success("‚úÖ Model loaded th√†nh c√¥ng!")
        return gen
    except Exception as e:
        st.error(f"‚ùå L·ªói load model: {e}")
        return None

def preprocess_image_region(image_region):
    # Chuy·ªÉn ƒë·ªïi ·∫£nh v·ªÅ grayscale (1 k√™nh)
    if len(image_region.shape) == 3:
        # N·∫øu ·∫£nh c√≥ 3 k√™nh (RGB), chuy·ªÉn v·ªÅ grayscale
        image_region = cv2.cvtColor(image_region, cv2.COLOR_RGB2GRAY)
    
    # Resize v·ªÅ 256x256
    resized = cv2.resize(image_region, (256, 256), interpolation=cv2.INTER_CUBIC)
    
    # Normalize v·ªÅ [-1, 1]
    normalized = (resized.astype(np.float32) / 127.5) - 1.0
    
    # T·∫°o tensor v·ªõi 1 k√™nh: [1, 1, 256, 256]
    tensor = torch.FloatTensor(normalized).unsqueeze(0).unsqueeze(0)
    
    return tensor

def postprocess_output(output_tensor, out_shape=None):
    output = (output_tensor.squeeze().detach().cpu().numpy() + 1.0) * 127.5
    output = np.clip(output, 0, 255).astype(np.uint8)
    if output.ndim == 3 and output.shape[0] == 3:
        output = np.transpose(output, (1, 2, 0))
    if out_shape is not None and (output.shape[0] != out_shape[0] or output.shape[1] != out_shape[1]):
        output = cv2.resize(output, (out_shape[1], out_shape[0]), interpolation=cv2.INTER_CUBIC)
    return output

def enhance_image_region(model, image_region):
    try:
        device = next(model.parameters()).device
        input_tensor = preprocess_image_region(image_region).to(device)
        with torch.no_grad():
            out = model(input_tensor)
        # Chuy·ªÉn v·ªÅ ƒë√∫ng shape patch g·ªëc
        enhanced_image = postprocess_output(out, out_shape=image_region.shape[:2])
        return enhanced_image
    except Exception as e:
        st.error(f"L·ªói khi enhance: {str(e)}")
        return None

def extract_32x32_patches(img, box, patch_size=32):
    """
    Tr√≠ch xu·∫•t t·∫•t c·∫£ patches 32x32 t·ª´ m·ªôt v√πng l·ªõn h∆°n
    """
    x1, y1, x2, y2 = box
    region_width = x2 - x1
    region_height = y2 - y1
    
    patches = []
    patch_positions = []
    
    # T√≠nh s·ªë patches theo chi·ªÅu ngang v√† d·ªçc
    num_patches_x = math.ceil(region_width / patch_size)
    num_patches_y = math.ceil(region_height / patch_size)
    
    for i in range(num_patches_y):
        for j in range(num_patches_x):
            # T√≠nh v·ªã tr√≠ patch
            patch_x1 = x1 + j * patch_size
            patch_y1 = y1 + i * patch_size
            patch_x2 = min(patch_x1 + patch_size, x2)
            patch_y2 = min(patch_y1 + patch_size, y2)
            
            # Crop patch t·ª´ ·∫£nh g·ªëc
            patch = img[patch_y1:patch_y2, patch_x1:patch_x2]
            
            # N·∫øu patch nh·ªè h∆°n 32x32, pad l·∫°i
            if patch.shape[0] < patch_size or patch.shape[1] < patch_size:
                patch = cv2.copyMakeBorder(
                    patch, 
                    0, patch_size - patch.shape[0], 
                    0, patch_size - patch.shape[1], 
                    borderType=cv2.BORDER_REFLECT
                )
            
            # ƒê·∫£m b·∫£o patch l√† grayscale (2D)
            if len(patch.shape) == 3:
                patch = cv2.cvtColor(patch, cv2.COLOR_RGB2GRAY)
            
            patches.append(patch)
            patch_positions.append((patch_x1, patch_y1, patch_x2, patch_y2))
    
    return patches, patch_positions

def reconstruct_enhanced_region(enhanced_patches, patch_positions, original_box, original_image_shape):
    """
    Gh√©p c√°c patches ƒë√£ tƒÉng c∆∞·ªùng l·∫°i th√†nh v√πng ho√†n ch·ªânh
    """
    x1, y1, x2, y2 = original_box
    region_width = x2 - x1
    region_height = y2 - y1
    
    # T·∫°o canvas ƒë·ªÉ gh√©p patches (grayscale)
    reconstructed_region = np.zeros((region_height, region_width), dtype=np.uint8)
    
    for enhanced_patch, (px1, py1, px2, py2) in zip(enhanced_patches, patch_positions):
        # T√≠nh v·ªã tr√≠ t∆∞∆°ng ƒë·ªëi trong v√πng
        rel_x1 = px1 - x1
        rel_y1 = py1 - y1
        rel_x2 = px2 - x1
        rel_y2 = py2 - y1
        
        # ƒê·∫£m b·∫£o kh√¥ng v∆∞·ª£t qu√° boundaries
        rel_x2 = min(rel_x2, region_width)
        rel_y2 = min(rel_y2, region_height)
        
        # Crop patch theo k√≠ch th∆∞·ªõc th·ª±c t·∫ø c·∫ßn thi·∫øt
        actual_width = rel_x2 - rel_x1
        actual_height = rel_y2 - rel_y1
        
        if actual_width > 0 and actual_height > 0:
            cropped_patch = enhanced_patch[:actual_height, :actual_width]
            reconstructed_region[rel_y1:rel_y2, rel_x1:rel_x2] = cropped_patch
    
    return reconstructed_region

def calculate_display_size(orig_w, orig_h, max_size=600):
    """T√≠nh to√°n k√≠ch th∆∞·ªõc hi·ªÉn th·ªã gi·ªØ nguy√™n t·ª∑ l·ªá"""
    if orig_w > orig_h:
        if orig_w > max_size:
            display_w = max_size
            display_h = int(orig_h * max_size / orig_w)
        else:
            display_w = orig_w
            display_h = orig_h
    else:
        if orig_h > max_size:
            display_h = max_size
            display_w = int(orig_w * max_size / orig_h)
        else:
            display_w = orig_w
            display_h = orig_h
    return display_w, display_h

def extract_boxes(canvas_result, display_w, display_h, orig_w, orig_h):
    """Tr√≠ch xu·∫•t t·∫•t c·∫£ bounding boxes (kh√¥ng gi·ªõi h·∫°n s·ªë l∆∞·ª£ng)"""
    boxes = []
    if canvas_result.json_data is not None:
        objects = canvas_result.json_data.get("objects", [])
        for obj in objects:
            if obj["type"] == "rect":
                left = int(obj["left"] * orig_w / display_w)
                top = int(obj["top"] * orig_h / display_h)
                width = int(obj["width"] * orig_w / display_w)
                height = int(obj["height"] * orig_h / display_h)
                x1, y1, x2, y2 = left, top, left+width, top+height
                boxes.append((x1, y1, x2, y2))
    return boxes

def validate_coordinates(x1, y1, x2, y2, img_width, img_height):
    """Ki·ªÉm tra t·ªça ƒë·ªô c√≥ h·ª£p l·ªá kh√¥ng"""
    if x1 < 0 or y1 < 0 or x2 < 0 or y2 < 0:
        return False, "T·ªça ƒë·ªô kh√¥ng ƒë∆∞·ª£c √¢m"
    if x1 >= x2 or y1 >= y2:
        return False, "x2 ph·∫£i l·ªõn h∆°n x1 v√† y2 ph·∫£i l·ªõn h∆°n y1"
    if x2 > img_width or y2 > img_height:
        return False, f"T·ªça ƒë·ªô v∆∞·ª£t qu√° k√≠ch th∆∞·ªõc ·∫£nh ({img_width}x{img_height})"
    return True, "T·ªça ƒë·ªô h·ª£p l·ªá"

def visualize_boxes_on_image(image_np, boxes):
    """V·∫Ω t·∫•t c·∫£ bounding boxes l√™n ·∫£nh"""
    img_vis = image_np.copy()
    for i, (x1, y1, x2, y2) in enumerate(boxes):
        cv2.rectangle(img_vis, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(img_vis, f'Region {i+1}', (x1, max(10, y1-10)),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    return img_vis

# ========== MAIN STREAMLIT APP ==========
st.markdown('<h1 style="text-align:center">ü©ª Demo TƒÉng C∆∞·ªùng Ch·∫•t L∆∞·ª£ng ·∫¢nh X-RAY b·∫±ng R3GAN</h1>', unsafe_allow_html=True)

# ===== MODEL STATUS =====
st.markdown("---")
st.header("ü§ñ Tr·∫°ng th√°i Model")
model = load_model()

if not model:
    st.error("‚ùå Model ch∆∞a ƒë∆∞·ª£c load th√†nh c√¥ng")
    st.stop()

# ===== TABS =====
tab1, tab2 = st.tabs(["üé® Khoanh V√πng Th·ªß C√¥ng", "üìù Nh·∫≠p T·ªça ƒê·ªô"])

# ========== TAB 1: MANUAL ENHANCEMENT ==========
with tab1:
    st.header("üìã H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng")
    with st.expander("üëâ Xem h∆∞·ªõng d·∫´n chi ti·∫øt", expanded=False):
        st.markdown("""
        **B∆∞·ªõc 1:** Upload ·∫£nh X-ray c·ªßa b·∫°n
        
        **B∆∞·ªõc 2:** V·∫Ω c√°c v√πng c·∫ßn tƒÉng c∆∞·ªùng
        
        **B∆∞·ªõc 3:** Nh·∫•n n√∫t "üöÄ TƒÉng C∆∞·ªùng" ƒë·ªÉ x·ª≠ l√Ω t·∫•t c·∫£ v√πng
        
        **L∆∞u √Ω:** N·∫øu v√πng l·ªõn h∆°n 32x32, h·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông chia th√†nh nhi·ªÅu patch 32x32 ƒë·ªÉ x·ª≠ l√Ω, sau ƒë√≥ gh√©p l·∫°i th√†nh v√πng ho√†n ch·ªânh
        """)

    # ===== UPLOAD ·∫¢NH =====
    st.markdown("---")
    st.header("üì§ Upload ·∫£nh X-ray")
    uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh X-ray", type=["png", "jpg", "jpeg", "bmp", "tiff"], key="manual_upload")

    if not uploaded_file:
        st.info("üìÅ Vui l√≤ng upload ·∫£nh X-ray ƒë·ªÉ b·∫Øt ƒë·∫ßu")
    else:
        # Load v√† hi·ªÉn th·ªã ·∫£nh g·ªëc
        image = Image.open(uploaded_file).convert("L")
        image_np = np.array(image)

        # T√≠nh to√°n k√≠ch th∆∞·ªõc hi·ªÉn th·ªã gi·ªØ nguy√™n t·ª∑ l·ªá
        orig_w, orig_h = image.size
        display_w, display_h = calculate_display_size(orig_w, orig_h)

        st.success(f"‚úÖ ƒê√£ upload th√†nh c√¥ng! K√≠ch th∆∞·ªõc g·ªëc: {orig_w}x{orig_h}")
        st.info(f"üìê K√≠ch th∆∞·ªõc hi·ªÉn th·ªã: {display_w}x{display_h}")

        # ===== V·∫º V√ôNG C·∫¶N X·ª¨ L√ç =====
        st.markdown("---")
        st.header("üñ±Ô∏è V·∫Ω v√πng c·∫ßn x·ª≠ l√Ω")
        st.markdown("**H∆∞·ªõng d·∫´n:** K√©o chu·ªôt ƒë·ªÉ t·∫°o h√¨nh ch·ªØ nh·∫≠t quanh c√°c v√πng b·∫°n mu·ªën tƒÉng ch·∫•t l∆∞·ª£ng.")

        # Canvas ƒë·ªÉ v·∫Ω bounding boxes
        canvas_result = st_canvas(
            fill_color="rgba(0, 255, 0, 0.2)",
            stroke_width=2,
            stroke_color="#00FF00",
            background_image=image,
            update_streamlit=True,
            height=display_h,
            width=display_w,
            drawing_mode="rect",
            key="manual_canvas",
        )

        # Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng v√πng ƒë√£ ch·ªçn
        if canvas_result.json_data is not None:
            num_boxes = len([obj for obj in canvas_result.json_data.get("objects", []) if obj["type"] == "rect"])
            if num_boxes > 0:
                st.success(f"üìç ƒê√£ ch·ªçn {num_boxes} v√πng ƒë·ªÉ x·ª≠ l√Ω")
            else:
                st.info("‚úèÔ∏è Ch∆∞a c√≥ v√πng n√†o ƒë∆∞·ª£c ch·ªçn. V·∫Ω h√¨nh ch·ªØ nh·∫≠t tr√™n ·∫£nh ƒë·ªÉ ch·ªçn v√πng c·∫ßn x·ª≠ l√Ω.")

        # ===== X·ª¨ L√ù V√Ä K·∫æT QU·∫¢ =====
        st.markdown("---")
        st.header("üöÄ X·ª≠ l√Ω")

        if canvas_result and canvas_result.json_data is not None:
            boxes = extract_boxes(canvas_result, display_w, display_h, orig_w, orig_h)
            
            if not boxes:
                st.warning("‚ö†Ô∏è Vui l√≤ng v·∫Ω √≠t nh·∫•t m·ªôt v√πng tr√™n ·∫£nh ƒë·ªÉ b·∫Øt ƒë·∫ßu x·ª≠ l√Ω")
            else:
                # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ patches s·∫Ω ƒë∆∞·ª£c t·∫°o
                total_patches = 0
                for i, box in enumerate(boxes):
                    x1, y1, x2, y2 = box
                    region_width = x2 - x1
                    region_height = y2 - y1
                    num_patches = math.ceil(region_width / 32) * math.ceil(region_height / 32)
                    total_patches += num_patches
                    st.info(f"üìä V√πng {i+1}: {region_width}x{region_height} ‚Üí {num_patches} patches 32x32")
                
                st.info(f"üìã T·ªïng c·ªông: {total_patches} patches s·∫Ω ƒë∆∞·ª£c x·ª≠ l√Ω")
                
                # N√∫t x·ª≠ l√Ω
                if st.button("üöÄ TƒÉng C∆∞·ªùng", type="primary", use_container_width=True, key="manual_enhance"):
                    st.markdown("---")
                    st.subheader(f"üîÑ X·ª≠ l√Ω {len(boxes)} v√πng...")
                    
                    # Progress bar
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # Container cho t·∫•t c·∫£ k·∫øt qu·∫£
                    results_container = st.container()
                    
                    with results_container:
                        processed_patches = 0
                        
                        # X·ª≠ l√Ω t·ª´ng v√πng
                        for i, box in enumerate(boxes):
                            st.markdown(f"### üîç V√πng {i+1}")
                            x1, y1, x2, y2 = box
                            region_width = x2 - x1
                            region_height = y2 - y1
                            
                            # Tr√≠ch xu·∫•t t·∫•t c·∫£ patches 32x32 t·ª´ v√πng n√†y
                            patches, patch_positions = extract_32x32_patches(image_np, box)
                            
                            st.info(f"üìè K√≠ch th∆∞·ªõc v√πng: {region_width}x{region_height}")
                            st.info(f"üì¶ S·ªë patches: {len(patches)}")
                            
                            # TƒÉng c∆∞·ªùng t·ª´ng patch
                            enhanced_patches = []
                            for patch_idx, patch in enumerate(patches):
                                # Update progress
                                progress = (processed_patches + 1) / total_patches
                                progress_bar.progress(progress)
                                status_text.text(f"ƒêang x·ª≠ l√Ω patch {processed_patches + 1}/{total_patches}...")
                                
                                # Enhancement
                                enhanced = enhance_image_region(model, patch)
                                if enhanced is not None:
                                    enhanced_patches.append(enhanced)
                                else:
                                    enhanced_patches.append(patch)  # Fallback to original if failed
                                
                                processed_patches += 1
                            
                            # Gh√©p l·∫°i v√πng ho√†n ch·ªânh
                            original_region = image_np[y1:y2, x1:x2]
                            enhanced_region = reconstruct_enhanced_region(enhanced_patches, patch_positions, box, image_np.shape)
                            
                            # Hi·ªÉn th·ªã k·∫øt qu·∫£ so s√°nh
                            col1, col2 = st.columns(2)
                            with col1:
                                st.image(original_region, caption=f"V√πng g·ªëc {i+1}", use_column_width=True)
                            with col2:
                                st.image(enhanced_region, caption=f"V√πng tƒÉng c∆∞·ªùng {i+1}", use_column_width=True)
                            
                            # Hi·ªÉn th·ªã chi ti·∫øt patches n·∫øu c·∫ßn
                            with st.expander(f"Xem chi ti·∫øt patches v√πng {i+1}", expanded=False):
                                cols_per_row = 4
                                for patch_idx, (original_patch, enhanced_patch, pos) in enumerate(zip(patches, enhanced_patches, patch_positions)):
                                    if patch_idx % cols_per_row == 0:
                                        cols = st.columns(cols_per_row)
                                    
                                    col_idx = patch_idx % cols_per_row
                                    with cols[col_idx]:
                                        st.markdown(f"**Patch {patch_idx + 1}**")
                                        st.image(original_patch, caption="G·ªëc", use_column_width=True)
                                        st.image(enhanced_patch, caption="TƒÉng c∆∞·ªùng", use_column_width=True)
                                        px1, py1, px2, py2 = pos
                                        st.caption(f"V·ªã tr√≠: ({px1},{py1}) - ({px2},{py2})")
                            
                            # Th√™m separator gi·ªØa c√°c v√πng
                            if i < len(boxes) - 1:
                                st.markdown("---")
                        
                        # Ho√†n th√†nh
                        progress_bar.progress(1.0)
                        status_text.text("‚úÖ Ho√†n th√†nh x·ª≠ l√Ω t·∫•t c·∫£ v√πng!")
                        st.success(f"üéâ ƒê√£ tƒÉng c∆∞·ªùng th√†nh c√¥ng {total_patches} patches t·ª´ {len(boxes)} v√πng!")
        else:
            st.info("‚úèÔ∏è V·∫Ω v√πng c·∫ßn tƒÉng c∆∞·ªùng tr√™n ·∫£nh, sau ƒë√≥ nh·∫•n n√∫t TƒÉng C∆∞·ªùng ƒë·ªÉ x·ª≠ l√Ω.")

# ========== TAB 2: COORDINATE INPUT ==========
with tab2:
    st.header("üìù Nh·∫≠p T·ªça ƒê·ªô V√πng")
    st.markdown("""
    T√≠nh nƒÉng n√†y cho ph√©p b·∫°n nh·∫≠p ch√≠nh x√°c t·ªça ƒë·ªô c·ªßa c√°c v√πng c·∫ßn tƒÉng c∆∞·ªùng.
    H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông chia v√πng l·ªõn th√†nh nhi·ªÅu patches 32x32 ƒë·ªÉ x·ª≠ l√Ω, sau ƒë√≥ gh√©p l·∫°i th√†nh v√πng ho√†n ch·ªânh.
    """)
    
    # ===== UPLOAD ·∫¢NH =====
    st.markdown("---")
    st.subheader("üìÅ Upload ·∫£nh X-ray")
    coord_image = st.file_uploader("Ch·ªçn ·∫£nh X-ray", 
                                 type=["png", "jpg", "jpeg", "bmp", "tiff"], 
                                 key="coord_image")
    
    if not coord_image:
        st.info("üìÅ Vui l√≤ng upload ·∫£nh X-ray ƒë·ªÉ ti·∫øp t·ª•c")
    else:
        # Load image
        image = Image.open(coord_image).convert("RGB")
        image_np = np.array(image)
        orig_w, orig_h = image.size
        display_w, display_h = calculate_display_size(orig_w, orig_h)
        
        st.success(f"‚úÖ ƒê√£ upload ·∫£nh: {coord_image.name} ({orig_w}x{orig_h})")
        
        # Hi·ªÉn th·ªã ·∫£nh g·ªëc
        st.image(image, caption="·∫¢nh g·ªëc", use_column_width=True)
        
        # ===== QU·∫¢N L√ù V√ôNG =====
        st.markdown("---")
        st.subheader("üìç Qu·∫£n l√Ω v√πng")
        
        # Initialize regions in session state v·ªõi key unique cho tab n√†y
        if 'coord_regions' not in st.session_state:
            st.session_state.coord_regions = []
        
        # Form ƒë·ªÉ th√™m v√πng m·ªõi
        st.markdown("**Th√™m v√πng m·ªõi:**")
        col1, col2, col3, col4, col5 = st.columns([2, 2, 2, 2, 1])
        
        with col1:
            new_x1 = st.number_input("X1", min_value=0, max_value=orig_w-1, value=0, key="coord_new_x1")
        with col2:
            new_y1 = st.number_input("Y1", min_value=0, max_value=orig_h-1, value=0, key="coord_new_y1")
        with col3:
            new_x2 = st.number_input("X2", min_value=1, max_value=orig_w, value=min(32, orig_w), key="coord_new_x2")
        with col4:
            new_y2 = st.number_input("Y2", min_value=1, max_value=orig_h, value=min(32, orig_h), key="coord_new_y2")
        with col5:
            add_region_clicked = st.button("‚ûï Th√™m", key="add_region_btn")
        
        if add_region_clicked:
            # Validate coordinates
            is_valid, message = validate_coordinates(new_x1, new_y1, new_x2, new_y2, orig_w, orig_h)
            
            if is_valid:
                st.session_state.coord_regions.append((new_x1, new_y1, new_x2, new_y2))
                st.success(f"‚úÖ ƒê√£ th√™m v√πng: ({new_x1}, {new_y1}) - ({new_x2}, {new_y2})")
                # st.rerun()
            else:
                st.error(f"‚ùå {message}")
        
        # Hi·ªÉn th·ªã danh s√°ch v√πng hi·ªán t·∫°i
        if st.session_state.coord_regions:
            st.markdown("**Danh s√°ch v√πng hi·ªán t·∫°i:**")
            
            # Hi·ªÉn th·ªã ·∫£nh v·ªõi t·∫•t c·∫£ bounding boxes
            img_with_boxes = visualize_boxes_on_image(image_np, st.session_state.coord_regions)
            st.image(img_with_boxes, caption=f"·∫¢nh v·ªõi {len(st.session_state.coord_regions)} v√πng", use_column_width=True)
            
            # Hi·ªÉn th·ªã chi ti·∫øt t·ª´ng v√πng
            for i, (x1, y1, x2, y2) in enumerate(st.session_state.coord_regions):
                width = x2 - x1
                height = y2 - y1
                num_patches = math.ceil(width / 32) * math.ceil(height / 32)
                
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.write(f"**V√πng {i+1}:** ({x1}, {y1}) - ({x2}, {y2}) | "
                            f"K√≠ch th∆∞·ªõc: {width}x{height} | "
                            f"Patches: {num_patches}")
                with col2:
                    if st.button("üóëÔ∏è", key=f"coord_delete_{i}", help="X√≥a v√πng n√†y"):
                        st.session_state.coord_regions.pop(i)
                        # st.rerun()
            
            # T√≠nh t·ªïng s·ªë patches
            total_patches = sum(math.ceil((x2-x1) / 32) * math.ceil((y2-y1) / 32) 
                              for x1, y1, x2, y2 in st.session_state.coord_regions)
            st.info(f"üìä T·ªïng c·ªông: {total_patches} patches s·∫Ω ƒë∆∞·ª£c x·ª≠ l√Ω")
            
            # N√∫t x√≥a t·∫•t c·∫£
            if st.button("üóëÔ∏è X√≥a t·∫•t c·∫£ v√πng", type="secondary", key="coord_clear_all"):
                st.session_state.coord_regions = []
                # st.rerun()
            
            # ===== X·ª¨ L√ù TƒÇNG C∆Ø·ªúNG =====
            st.markdown("---")
            st.subheader("üöÄ TƒÉng c∆∞·ªùng ch·∫•t l∆∞·ª£ng")
            
            if st.button("üöÄ TƒÉng C∆∞·ªùng T·∫•t C·∫£ V√πng", 
                        type="primary", use_container_width=True, key="coord_enhance"):
                
                st.markdown("---")
                st.subheader(f"üîÑ ƒêang x·ª≠ l√Ω {len(st.session_state.coord_regions)} v√πng...")
                
                # Progress bar
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Container cho t·∫•t c·∫£ k·∫øt qu·∫£
                results_container = st.container()
                
                with results_container:
                    processed_patches = 0
                    
                    # X·ª≠ l√Ω t·ª´ng v√πng
                    for i, box in enumerate(st.session_state.coord_regions):
                        st.markdown(f"### üîç V√πng {i+1}")
                        x1, y1, x2, y2 = box
                        region_width = x2 - x1
                        region_height = y2 - y1
                        
                        # Tr√≠ch xu·∫•t t·∫•t c·∫£ patches 32x32 t·ª´ v√πng n√†y
                        patches, patch_positions = extract_32x32_patches(image_np, box)
                        
                        st.info(f"üìè K√≠ch th∆∞·ªõc v√πng: {region_width}x{region_height}")
                        st.info(f"üì¶ S·ªë patches: {len(patches)}")
                        
                        # Enhance t·ª´ng patch
                        enhanced_patches = []
                        for patch_idx, patch in enumerate(patches):
                            progress = (processed_patches + 1) / total_patches
                            progress_bar.progress(progress)
                            status_text.text(f"ƒêang x·ª≠ l√Ω patch {processed_patches + 1}/{total_patches}...")
                            enhanced = enhance_image_region(model, patch)
                            enhanced_patches.append(enhanced if enhanced is not None else patch)
                            processed_patches += 1

                        # Gh√©p l·∫°i th√†nh v√πng l·ªõn ƒë√£ tƒÉng c∆∞·ªùng
                        original_region = image_np[y1:y2, x1:x2]
                        enhanced_region = reconstruct_enhanced_region(enhanced_patches, patch_positions, box, image_np.shape)

                        # Hi·ªÉn th·ªã k·∫øt qu·∫£ so s√°nh
                        col1, col2 = st.columns(2)
                        with col1:
                            st.image(original_region, caption=f"V√πng g·ªëc {i+1}", use_column_width=True)
                        with col2:
                            st.image(enhanced_region, caption=f"V√πng tƒÉng c∆∞·ªùng {i+1}", use_column_width=True)

                        # Xem chi ti·∫øt patch n·∫øu c·∫ßn
                        with st.expander(f"Xem chi ti·∫øt patches v√πng {i+1}", expanded=False):
                            cols_per_row = 4
                            for patch_idx, (original_patch, enhanced_patch, pos) in enumerate(zip(patches, enhanced_patches, patch_positions)):
                                if patch_idx % cols_per_row == 0:
                                    cols = st.columns(cols_per_row)
                                col_idx = patch_idx % cols_per_row
                                with cols[col_idx]:
                                    st.markdown(f"**Patch {patch_idx + 1}**")
                                    st.image(original_patch, caption="G·ªëc", use_column_width=True)
                                    st.image(enhanced_patch, caption="TƒÉng c∆∞·ªùng", use_column_width=True)
                                    px1, py1, px2, py2 = pos
                                    st.caption(f"V·ªã tr√≠: ({px1},{py1}) - ({px2},{py2})")

                        # Separator
                        if i < len(st.session_state.coord_regions) - 1:
                            st.markdown("---")

                    # Ho√†n th√†nh
                    progress_bar.progress(1.0)
                    status_text.text("‚úÖ ƒê√£ ho√†n th√†nh tƒÉng c∆∞·ªùng t·∫•t c·∫£ v√πng!")
                    st.success(f"üéâ ƒê√£ tƒÉng c∆∞·ªùng th√†nh c√¥ng {total_patches} patches t·ª´ {len(st.session_state.coord_regions)} v√πng!")